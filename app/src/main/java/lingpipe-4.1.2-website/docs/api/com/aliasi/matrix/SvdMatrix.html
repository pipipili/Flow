<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_45) on Sun Dec 04 16:36:12 EST 2016 -->
<title>SvdMatrix (LingPipe API)</title>
<meta name="date" content="2016-12-04">
<link rel="stylesheet" type="text/css" href="../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="SvdMatrix (LingPipe API)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":9,"i5":10,"i6":10,"i7":10,"i8":9,"i9":10};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../com/aliasi/matrix/SparseFloatVector.html" title="class in com.aliasi.matrix"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../com/aliasi/matrix/TaxicabDistance.html" title="class in com.aliasi.matrix"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?com/aliasi/matrix/SvdMatrix.html" target="_top">Frames</a></li>
<li><a href="SvdMatrix.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">com.aliasi.matrix</div>
<h2 title="Class SvdMatrix" class="title">Class SvdMatrix</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">java.lang.Object</a></li>
<li>
<ul class="inheritance">
<li><a href="../../../com/aliasi/matrix/AbstractMatrix.html" title="class in com.aliasi.matrix">com.aliasi.matrix.AbstractMatrix</a></li>
<li>
<ul class="inheritance">
<li>com.aliasi.matrix.SvdMatrix</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd><a href="../../../com/aliasi/matrix/Matrix.html" title="interface in com.aliasi.matrix">Matrix</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">SvdMatrix</span>
extends <a href="../../../com/aliasi/matrix/AbstractMatrix.html" title="class in com.aliasi.matrix">AbstractMatrix</a></pre>
<div class="block">An <code>SvdMatrix</code> provides a means of storing a matrix that
 has been factored via a singular-value decomposition (SVD).  This
 class also provides a static method for computing regularized
 singular-value decompositions of partial matrices.

 <h3>Singular Value Decomposition</h3>

 <p>Singular value decomposition (SVD) factors an
 <code>m&times;n</code> matrix <code>A</code> into a product of
 three matrices:

 <blockquote><pre>
 A = U * S * V<sup><sup>T</sup></sup></pre></blockquote>

 where <code>U</code> is an <code>m&times;k</code> matrix,
 <code>V</code> is an <code>n&times;k</code> matrix, and
 <code>S</code> is a <code>k&times;k</code> matrix, where
 <code>k</code> is the rank of the matrix <code>A</code>.  The
 multiplication (<code>*</code>) is matrix multiplication and
 the superscripted <code>T</code> indicates matrix transposition.

 <p>The <code>m</code>-dimensional vectors making up the columns of
 <code>U</code> are called left singular vectors, whereas
 the <code>n</code>-dimesnional vectors making up the rows of
 <code>V</code> are called right singular vectors.  The values on
 the diagonal of <code>S</code> are called the singular values.
 The combination of the <code>q</code>-th left singular vector,
 right singular vector, and singular value is known as a factor.

 <p>The singular value matrix <code>S</code> is a diagonal matrix
 with positive, strictly non-increasing values, so that
 <code>S[i][i] &gt;= S[i+1][i+1]</code>, for <code>i &lt; k</code>.
 The set of left and set of right singular vectors are orthonormal.
 Normality means that each singular vector is of unit length (length
 <code>1</code>).  Orthogonality means that any pair of left singular
 vectors is orthogonal and any pair of right singular vectors are
 orthogonal (meaning their dot product is <code>0</code>).

 <p>Matrices have unique singular-value decompositions
 up to the re-ordering of columns with equal singular values and
 up to cancelling sign changes in the singular vectors.

 <h3>Construction and Value Computation</h3>

 An <code>SvdMatrix</code> may be constructed out of the singular
 vectors and singular values, or out of the vectors with singular
 values scaled in.

 <p>Given that <code>S</code> is diagonal, the value of a particular
 entry in <code>A</code> works out to:

 <blockquote><pre>
 A[i][j] = <big>&Sigma;</big><sub>k</sub></code> U[i][k] * S[k][k] * V[j][k]</pre></blockquote>

 To save time in the application and space in the class,
 we factor <code>S</code> into <code>U</code> and <code>V</code>
 to produce a new pair of matrices <code>U'</code> and <code>V'</code>
 defined by:

 <blockquote><pre>
 U' = U * sqrt(S)
 V'<sup>T</sup> = sqrt(S) * V<sup>T</sup></pre></blockquote>

 with the square-root performed component-wise:

 <blockquote><pre>
 sqrt(S)[i][j] = sqrt(S[i][j])</pre></blockquote>

 By the associativity of matrix multiplication, we have:

 <blockquote><pre>
 U * S * V<sup>T</sup>
 = U * sqrt(S) * sqrt(S) * V
 = U' * V'<sup>T</sup></pre></blockquote>

 <p>Thus the class implementation is able to store <code>U'</code>
 and <code>V'</code>, thus reducing the amount computation involved
 in returning a value (using column vectors as the default vector
 orientation):

 <blocqkuote><pre>
 A[i][j] = U'[i]<sup>T</sup> * V'[j]</pre></blockquote>


 <h3>Square Error and the Frobenius Norm</h3>

 Suppose <code>A</code> and <code>B</code> are
 <code>m&times;n</code> matrices.  The square error between them is
 defined by the so-called Frobenius norm, which extends the standard
 vector L<sub>2</sub> or Euclidean norm to matrices:

 <blockquote><pre>
 squareError(A,B)

 = frobeniusNorm(A-B)

 = <big>&Sigma;</big><sub>i &lt; m</sub> <big>&Sigma;</big><sub>j &lt; n</sub> (A[i][j] - B[i][j])<sup>2</sup></pre></blockquote>

 The square error is sometimes referred to as the residual sum
 of squares (RSS), because <code>A[i][j] - B[i][j]</code>
 is the residual (difference between actual and predicted value).

 <h3>Lower-order Approximations</h3>

 Consider factoring a matrix <code>A</code> of dimension
 <code>m&times;n</code> into the product of two matrices
 <code>X * Y<sup>T</sup></code>, where <code>X</code> is of dimension
 <code>m&times;k</code> and <code>Y</code> is of dimension
 <code>n&times;k</code>.  We may then measure the square
 error <code>squareError(A,X * Y)</code> to determine how well
 the factorization matches <code>A</code>.  We know that if
 we take <code>U', V'</code> from the singular value
 decomposition that:

 <blockquote><pre>
 squareError(A, U' * V'<sup>T</sup>) = 0.0</pre></blockquote>

 Here <code>U'</code> and <code>V'</code> have a number of columns
 (called factors) equal to the rank of the matrix <code>A</code>.
 The singular value decomposition is such that the first
 <code>k</code> columns of <code>U'</code> and <code>V'</code>
 provide the best order <code>q</code> approximation of
 <code>A</code> of any <code>X</code> and <code>Y</code>
 of dimensions <code>m&times;q</code> and <code>n&times;q</code>
 In symbols:

 <blockquote><pre>
 U'<sub>q</sub>, V'<sub>q</sub> = argmin <sub>X is m&times;q, Y is n&times;q</sub> squareError(A, X * Y<sup>T</sup>)</pre></blockquote>

 where <code>U'<sub>q</sub></code> is the restriction of <code>U'</code>
 to its first <code>q</code> columns.

 <p>Often errors are reported as means, where the mean square error
 (MSE) is defined by:

 <blockquote><pre>
 meanSquareError(A,B) = squareError(A,B)/(m&times;n)</pre></blockquote>

 <p>To adjust to a linear scale, the square root of mean square
 error (RMSE) is often used:

 <blockquote><pre>
 rootMeanSquareError(A,B) = sqrt(meanSquareError(A,B))</pre></blockquote>


 <h3>Partial Matrices</h3>

 A partial matrix is one in which some of the values are unknown.
 This is in contrast with a sparse matrix, in which most of the
 values are zero.  A variant of singular value decomposition may be
 used to impute the unknown values by minimizing square error with
 respect to the known values only.  Unknown values are then simply
 derived from the factorization <code>U' * V'<sup>T</sup></code>.
 Typically, the approximation is of lower order than the rank of
 the matrix.

 <h3>Regularized SVD via Shrinkage</h3>

 Linear regression techniques such as SVD often overfit their
 training data in order to derive exact answers.  This problem
 is mitigated somewhat by choosing low-order approximations to
 the full-rank SVD.  Another option is to penalize large values
 in the singular vectors, thus favoring smaller values.  The
 most common way to do this because of its practicality is via
 parameter shrinkage.

 <p>Shrinkage is a general technique in least squares fitting that
 adds a penalty term proportional to the square of the size of
 the parameters.  Thus the square error objective function is
 replaced with a regularized version:

 <blockquote><pre>
 regularizedError(A, U' * V')

 = squareError(A, U' * V')

 + parameterCost(U') + parameterCost(V')</pre></blockquote>

 where the parameter costs for a vector <code>X</code> of
 dimensionality <code>q</code> is the sum of the squared
 parameters:

 <blockquote><pre>
 parameterCost(X)

 = &lambda; * <big>&Sigma;</big><sub>i &lt; q</sub> X[i]<sup>2</sup>

 = &lambda; * length(X)<sup>2</sup></pre></blockquote>

 Note that the hyperparameter <code>&lambda;</code> scales the
 parameter cost term in the overall error.

 <p>Setting the regularization parameter to zero sets the parameter
 costs to zero, resulting in an unregularized SVD computation.

 <p>In Bayesian terms, regularization is equivalent to a normal
 prior on parameter values centered on zero with variance controlled
 by <code>&lambda;</code>.  The resulting minimizer of regularized
 error is the maximum a posteriori (MAP) solution.  The Bayesian
 approach also allows covariances to be estimated (including simple
 parameter variance estimates), but these are not implemented in
 this class.


 <h3>Regularized Stochastic Gradient Descent</h3>

 Singular value decomposition may be computed &quot;exactly&quot;
 (modulo arithmetic precision and convergence) using an algorithm
 whose time complexity is <code>O(m<sup>3</sup> +
 n<sup>3</sup>)</code> for an <code>m&times;n</code> matrix (equal
 to <code>O(max(m,n)<sup>3</sup>)</code>.  Arithmetic precision is
 especially vexing at singular values near zero and with highly
 correlated rows or columns in the input matrix.

 <p>For large partial matrices, we use a form of stochastic gradient
 descent which computes a single row and column singular vector (a
 single factor, that is) at a time.  Each factor is estimated by
 iteratively visiting the data points and adjusting the unnormalized
 singular vectors making up the current factor.  Each adjustment is
 a least-squares fitting step, where we simultaneously adjust the
 left singular vectors given the right singular vectors and
 vice-versa.

 <p>The least-squares adjustments take the following form.  For each
 value, we compute the current error (using the order <code>k</code>
 approximation and the current order <code>k+1</code> values) and
 then move the vectors to reduce error.  We use <code>U'</code> and
 <code>V'</code> for the incremental values of the singular vectors
 scaled by the singular values:

 <blockquote><pre>
 for (k = 0; k &lt; maxOrder; ++k)
     for (i &lt; m) U'[i][k] = random.nextGaussian()*initValue;
     for (j &lt; n) V'[j][k] = random.nextGaussian()*initValue;
     for (epoch = 0; epoch &lt; maxEpochs &amp;&amp; not converged; ++epoch)
         for (i,j such that M[i][j] defined)
             error = M[i][j] - U'<sub>k</sub>[i] * V'<sub>k</sub>[j] <small>// * is vector dot product</small>
             uTemp = U'[i][k]
             vTemp = V'[j][k]
             U'[i][k] += learningRate[epoch] * ( error * vTemp - regularization * uTemp )
             V'[j][k] += learningRate[epoch] * ( error * uTemp - regularization * vTemp )</pre></blockquote>

 where <code>initValue</code>, <code>maxEpochs</code>,
 <code>learningRate</code> (see below), and
 <code>regularization</code> are algorithm hyperparameters.  Note
 that the initial values of the singular vectors are set randomly to
 the result of a draw from a Gaussian (normal) distribution with
 mean 0.0 and variance 1.0.

 <p>Because we use the entire set of
 factors in the error computation, the current factor is guaranteed
 to have singular vectors orthogonal to the singular vectors already
 computed.

 <p>Note that in the actual implementation, the contribution to the
 error of the first <code>k-1</code> factors is cached to reduce
 time in the inner loop.  This requires a double-length floating
 point value for each defined entry in the matrix.

 <h4>Gradient Interpretation</h4>

 <p>Like most linear learners, this algorithm merely moves the
 parameter vectors <code>U'[i]</code> and <code>U'[j]</code> in the
 direction of the gradient of the error.  The gradient is the
 multivariate derivative of the objective function being minimized.
 Because our object is squared error, the gradient is just its
 derivative, which is just (two times) the (linear) error itself.  We
 roll the factor of 2 into the learning rate to derive the update in
 the algorithm pseudo-code above.

 <p>The term <code>(error * vTemp)</code> is the component of the
 error gradient due to the current value of <code>V'[i][k]</code>
 and the term <code>(regularization * uTemp)</code> is the component of the
 gradient to the size of the parameter <code>U'[i][k]</code>.  The
 updates thus move the parameter vectors in the direction of
 the gradient.

 <h4>Convergence Conditions</h4>

 <p>The convergence conditions for a given factor require either
 hitting the maximum number of allowable epochs, or finding the
 improvement from one epoch to the next is below some relative
 threshold:

 <blockquote><pre>
 regError<sup>(epoch)</sup> = regError(M,U'<sub>k</sub><sup>(epoch)</sup> * V'<sub>k</sub><sup>(epoch)</sup><sup>T</sup>)

 relativeImprovement<sup>(epoch+1)</sup> = relativeDiff(regError<sup>(epoch+1)</sup>, regError<sup>(epoch)</sup>)

 relativeDiff(x,y) = abs(x-y)/(abs(x) + abs(y))</pre></blockquote>

 When the relative difference in square error is less than
 a hyperparameter threshold <code>minImprovement</code>, the
 epoch terminates and the algorithm moves on to the next
 factor <code>k+1</code>.

 <p>Note that a complete matrix is a degenerate kind of partial
 matrix.  The gradient descent computation still works in this
 situation, but is not as efficient or as accurate as an
 algebraic SVD solver for small matrices.

 <h3>Annealing Schedule</h3>

 Learning rates that are too high are unstable, whereas learning rates
 that are too low never reach their targets.  To get around this
 problem, the learning rate, <code>learningRate[epoch]</code>, is
 lowered as the number of epochs increase.  This lowering of the
 learning rate has a thermodynamic interpretation in terms of free
 energy, hence the name &quot;annealing&quot;.  Larger moves are
 made in earlier epochs, then the temperature is gradually lowered
 so that the learner may settle into a stable fixed point.  The
 function <code>learningRate[epoch]</code> is called the annealing
 schedule.

 <p>There are theoretical requirements on the annealing schedule
 that guarantee convergence (up to arithmetic precision and no upper
 bound on the number of epochs):

 <blockquote><pre>
 <big>&Sigma;</big><sub>epoch</sub> learningRate[epoch] = infinity

 <big>&Sigma;</big><sub>epoch</sub> learningRate[epoch]<sup>2</sup> &lt; infinity</pre></blockquote>

 The schedule we use is the one commonly chosen to meet the
 above requirements:

 <blockquote><pre>
 learningRate[epoch] = initialLearningRate / (1 + epoch/annealingRate)</pre></blockquote>

 where <code>initialLearningRate</code> is an initial learning rate and
 <code>annealingFactor</code> determines how quickly it shrinks.
 The learning rate moves from its initial size
 (<code>initialLearningRate</code>) to one half (<code>1/2</code>) of its
 original size after <code>annealingRate</code> epochs, and
 moves from its initial size to one tenth (<code>1/10</code>) of
 its initial size after <code>9 * annealingRate</code> epochs,
 and one hundredth of its initial size after
 <code>99 * annealingRate</code> epochs..

 <h3>Parameter Choices</h3>

 <p>The previous discussion has introduced a daunting list of
 parameters required for gradient descent for singular value
 decomposition.  Unfortunately, the stochastic gradient descent
 solver requires a fair amount of tuning to recover a low mean
 square error factorization.  The optimal settings will also depend
 on the input matrix; for example, very sparse partial matrices are
 much easier to fit than dense matrices.

 <h4>Maximum Order</h4>

 <p>Determining the order of the decomposition is mostly a matter
 of determining how many orders are needed for the amount of
 smoothing required.  Low order reconstructions are useful for
 most applications.  One way to determine maximum order is using
 held out data for an application.  Another is to look for
 a point where the singular values become (relatively) insignificant.


 <h4>Maximum Epochs and Early Stopping</h4>

 <p>For low mean square error factorizations, many epochs may be
 necessary.  Lowering the maximum number of epochs leads to what is
 known as early stopping.  Sometimes, early stopping leads to
 more accurate held-out predictions, but it will always raise
 the factorization error (training data predictions).  In general,
 the maximum number of epochs needs to be set empirically.
 Initially, try fewer epochs and gradually raise the number of
 epochs until the desired accuracy is achieved.

 <h4>Minimum Improvement</h4>

 By setting the minimum improvement to 0.0, the algorithm is forced
 to use the maximum number of epochs.  By setting it above this
 level, a form of early stopping is achieved when the benefit of
 another epoch of refitting falls below a given improvement
 threshold.  This value may also be set on an application basis
 using held out data, or it may be fit to achieve a given level of
 mean square error on the training (input) data.  The minimum
 improvement needs to be set fairly low (less than 0.000001) to
 achieve reasonably precise factorizations.  Note that minimum
 improvement is defined relatively, as noted above.

 <h4>Initial Parameter Values</h4>

 <p>Initial values of the singular vectors are not particularly
 sensitive, because we are using multiplicative updates.  A good
 rule of thumb for starting values is the the inverse square root of
 the maximum order:

 <blockquote><pre>
 initVal ~ 1 / sqrt(maxOrder)</pre></blockquote>

 <h4>Learning Rate, Maximum Epochs and Annealing</h4>

 <p>A good starting point for the learning rate is 0.01.  The
 annealing parameter should be set so that the learning rate is cut
 by at least a factor of 10 in the final rounds.  This calls for a
 value that's roughly one tenth of the maximum number of epochs.  If
 the initial learning rate is set higher, then the annealing
 schedule should be more agressive so that it spends a fair amount
 of time in the 0.001 to 0.0001 learning rate range.


 <h3>References</h3>

 <p>There are thorough Wikipedia articles on singular value decomposition
 and gradient descent, although the SVD entry focuses entirely on
 complete (non-partial) matrices:

 <ul>
 <li><a href="http://en.wikipedia.org/wiki/Singular_value_decomposition">Wikipedia: Singular Value Decomposition</a></li>
 <li><a href="http://en.wikipedia.org/wiki/Gradient_descent">Wikipedia: Gradient Descent</a></li>
 </ul>

 Both of the standard machine learning textbooks have good
 theoretical explanations of least squares, regularization,
 gradient descent, and singular value decomposition, but not
 all together:

 <ul>
 <li>Chris Bishop.  2007.  <i>Pattern Recognition and Machine Learning.</i>  Springer.</li>
 <li>Trevor Hastie, Robert Tibshirani, and Jerome Friedman.  2001.
 <i>The Elements of Statistical Learning</i>.  Springer.</i>
 </ul>

 <p>The following is a particularly clear explanation of many of
 the issues involved in the context of neural networks:

 <ul>
 <li>Genevieve Orr, Nici Schraudolph, and Fred Cummins.  1999.
<a href="http://www.willamette.edu/~gorr/classes/cs449/intro.html">CS-449: Neural Networks</a>.  Willamette University course notes.</li>
 </ul>

 <p>Our partial SVD solver is based on C code from Timely
 Development (see license below).  Timely based their code on Simon
 Funk's blog entry.  Simon Funk's approach was itself based on his
 and Genevieve Gorrell's 2005 EACL paper.

 <ul>
 <li><a href="http://www.timelydevelopment.com/Demos/NetflixPrize.htm">Timely Development's Netflix Prize Page</a>.
 <li>Simon Funk (pseudonym for Brandyn Webb). 2007.
 <a href="http://sifter.org/~simon/journal/20061211.html">Gradient Descent SVD Algorithm</a>.  <i>The Evolution of Cybernetics</i> blog.
 <li>Genevieve Gorrell.  2006.
 <a href="http://acl.ldc.upenn.edu/E/E06/E06-1013.pdf">Generalized Hebbian Algorithm for Incremental Singular Value
Decomposition in Natural Language Processing</a>.  EACL 2006.</li>
 <li>Genevieve Gorrell.  2006.
 <a href="http://www.dcs.shef.ac.uk/~genevieve/gorrell_thesis.pdf">Generalized Hebbian Algorithm for Dimensionality Reduction in Natural Language Processing</a>. Ph.D. Thesis.
 Link&#246;ping University.  Sweden.</li>
 </ul>

 <h3>Acknowledgements</h3>

 <p>The singular value decomposition code is rather loosely based on
 a C program developed by <a
 href="http://www.timelydevelopment.com/">Timely Development</a>.
 Here is the copyright notice for the original code:

 <blockquote><pre style="font-size:80%">
 // SVD Sample Code
 //
 // Copyright (C) 2007 Timely Development (www.timelydevelopment.com)
 //
 // Special thanks to Simon Funk and others from the Netflix Prize contest
 // for providing pseudo-code and tuning hints.
 //
 // Feel free to use this code as you wish as long as you include
 // these notices and attribution.
 //
 // Also, if you have alternative types of algorithms for accomplishing
 // the same goal and would like to contribute, please share them as well :)
 //
 // STANDARD DISCLAIMER:
 //
 // - THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY
 // - OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT
 // - LIMITED TO THE IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR
 // - FITNESS FOR A PARTICULAR PURPOSE.
 </pre></blockquote></div>
<dl>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>LingPipe3.2</dd>
<dt><span class="simpleTagLabel">Version:</span></dt>
<dd>4.0.0</dd>
<dt><span class="simpleTagLabel">Author:</span></dt>
<dd>Bob Carpenter</dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#SvdMatrix-double:A:A-double:A:A-double:A-">SvdMatrix</a></span>(double[][]&nbsp;rowSingularVectors,
         double[][]&nbsp;columnSingularVectors,
         double[]&nbsp;singularValues)</code>
<div class="block">Construct an SVD matrix using the specified singular vectors
 and singular values.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#SvdMatrix-double:A:A-double:A:A-int-">SvdMatrix</a></span>(double[][]&nbsp;rowVectors,
         double[][]&nbsp;columnVectors,
         int&nbsp;order)</code>
<div class="block">Construct a factored matrix using the specified row and column
 vectors at the specified order.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>double[][]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#leftSingularVectors--">leftSingularVectors</a></span>()</code>
<div class="block">Returns a matrix in which the left singular vectors make up the
 columns.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#numColumns--">numColumns</a></span>()</code>
<div class="block">Returns the number of columns in this matrix.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#numRows--">numRows</a></span>()</code>
<div class="block">Returns the number of rows in this matrix.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#order--">order</a></span>()</code>
<div class="block">Returns the order of this factorization.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>static <a href="../../../com/aliasi/matrix/SvdMatrix.html" title="class in com.aliasi.matrix">SvdMatrix</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#partialSvd-int:A:A-double:A:A-int-double-double-double-double-com.aliasi.io.Reporter-double-int-int-">partialSvd</a></span>(int[][]&nbsp;columnIds,
          double[][]&nbsp;values,
          int&nbsp;maxOrder,
          double&nbsp;featureInit,
          double&nbsp;initialLearningRate,
          double&nbsp;annealingRate,
          double&nbsp;regularization,
          <a href="../../../com/aliasi/io/Reporter.html" title="class in com.aliasi.io">Reporter</a>&nbsp;reporter,
          double&nbsp;minImprovement,
          int&nbsp;minEpochs,
          int&nbsp;maxEpochs)</code>
<div class="block">Return the singular value decomposition of the specified
 partial matrix, using the specified search parameters.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>double[][]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#rightSingularVectors--">rightSingularVectors</a></span>()</code>
<div class="block">Returns a matrix in which the right singular vectors make up
 the columns.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#singularValue-int-">singularValue</a></span>(int&nbsp;order)</code>
<div class="block">Returns the singular value for the specified order.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>double[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#singularValues--">singularValues</a></span>()</code>
<div class="block">Returns the array of singular values for this decomposition.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>static <a href="../../../com/aliasi/matrix/SvdMatrix.html" title="class in com.aliasi.matrix">SvdMatrix</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#svd-double:A:A-int-double-double-double-double-com.aliasi.io.Reporter-double-int-int-">svd</a></span>(double[][]&nbsp;values,
   int&nbsp;maxOrder,
   double&nbsp;featureInit,
   double&nbsp;initialLearningRate,
   double&nbsp;annealingRate,
   double&nbsp;regularization,
   <a href="../../../com/aliasi/io/Reporter.html" title="class in com.aliasi.io">Reporter</a>&nbsp;reporter,
   double&nbsp;minImprovement,
   int&nbsp;minEpochs,
   int&nbsp;maxEpochs)</code>
<div class="block">Returns the signular value decomposition of the specified
 complete matrix of values.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/matrix/SvdMatrix.html#value-int-int-">value</a></span>(int&nbsp;row,
     int&nbsp;column)</code>
<div class="block">Returns the value of this matrix at the specified row and column.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.com.aliasi.matrix.AbstractMatrix">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;com.aliasi.matrix.<a href="../../../com/aliasi/matrix/AbstractMatrix.html" title="class in com.aliasi.matrix">AbstractMatrix</a></h3>
<code><a href="../../../com/aliasi/matrix/AbstractMatrix.html#columnVector-int-">columnVector</a>, <a href="../../../com/aliasi/matrix/AbstractMatrix.html#equals-java.lang.Object-">equals</a>, <a href="../../../com/aliasi/matrix/AbstractMatrix.html#hashCode--">hashCode</a>, <a href="../../../com/aliasi/matrix/AbstractMatrix.html#rowVector-int-">rowVector</a>, <a href="../../../com/aliasi/matrix/AbstractMatrix.html#setValue-int-int-double-">setValue</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.<a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a></h3>
<code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#clone--" title="class or interface in java.lang">clone</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#finalize--" title="class or interface in java.lang">finalize</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#getClass--" title="class or interface in java.lang">getClass</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#notify--" title="class or interface in java.lang">notify</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#notifyAll--" title="class or interface in java.lang">notifyAll</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#toString--" title="class or interface in java.lang">toString</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait--" title="class or interface in java.lang">wait</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait-long-" title="class or interface in java.lang">wait</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait-long-int-" title="class or interface in java.lang">wait</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="SvdMatrix-double:A:A-double:A:A-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SvdMatrix</h4>
<pre>public&nbsp;SvdMatrix(double[][]&nbsp;rowVectors,
                 double[][]&nbsp;columnVectors,
                 int&nbsp;order)</pre>
<div class="block">Construct a factored matrix using the specified row and column
 vectors at the specified order.  Each vector in the arrays of
 row and column vectors must be of the same dimension as the
 order.

 <p>See the class documentation above for more information
 on singular value decomposition.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rowVectors</code> - Row vectors, indexed by row.</dd>
<dd><code>columnVectors</code> - Column vectors, indexed by column.</dd>
<dd><code>order</code> - Dimensionality of the row and column vectors.</dd>
</dl>
</li>
</ul>
<a name="SvdMatrix-double:A:A-double:A:A-double:A-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>SvdMatrix</h4>
<pre>public&nbsp;SvdMatrix(double[][]&nbsp;rowSingularVectors,
                 double[][]&nbsp;columnSingularVectors,
                 double[]&nbsp;singularValues)</pre>
<div class="block">Construct an SVD matrix using the specified singular vectors
 and singular values.  The order of the factorization is equal to
 the length of the singular values.  Each singular vector must
 be the same dimensionality as the array of singular values.

 <p>See the class documentation above for more information
 on singular value decomposition.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rowSingularVectors</code> - Row singular vectors, indexed by row.</dd>
<dd><code>columnSingularVectors</code> - Column singular vectors, indexed by column.</dd>
<dd><code>singularValues</code> - Array of singular values, in decreasing order.</dd>
</dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="numRows--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numRows</h4>
<pre>public&nbsp;int&nbsp;numRows()</pre>
<div class="block">Returns the number of rows in this matrix.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../com/aliasi/matrix/Matrix.html#numRows--">numRows</a></code>&nbsp;in interface&nbsp;<code><a href="../../../com/aliasi/matrix/Matrix.html" title="interface in com.aliasi.matrix">Matrix</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../com/aliasi/matrix/AbstractMatrix.html#numRows--">numRows</a></code>&nbsp;in class&nbsp;<code><a href="../../../com/aliasi/matrix/AbstractMatrix.html" title="class in com.aliasi.matrix">AbstractMatrix</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The number of rows in this matrix.</dd>
</dl>
</li>
</ul>
<a name="numColumns--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numColumns</h4>
<pre>public&nbsp;int&nbsp;numColumns()</pre>
<div class="block">Returns the number of columns in this matrix.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../com/aliasi/matrix/Matrix.html#numColumns--">numColumns</a></code>&nbsp;in interface&nbsp;<code><a href="../../../com/aliasi/matrix/Matrix.html" title="interface in com.aliasi.matrix">Matrix</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../com/aliasi/matrix/AbstractMatrix.html#numColumns--">numColumns</a></code>&nbsp;in class&nbsp;<code><a href="../../../com/aliasi/matrix/AbstractMatrix.html" title="class in com.aliasi.matrix">AbstractMatrix</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The number of columns in this matrix.</dd>
</dl>
</li>
</ul>
<a name="order--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>order</h4>
<pre>public&nbsp;int&nbsp;order()</pre>
<div class="block">Returns the order of this factorization.  The order
 is the number of dimensions in the singular vectors
 and the singular values.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The order of this decomposition.</dd>
</dl>
</li>
</ul>
<a name="value-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>value</h4>
<pre>public&nbsp;double&nbsp;value(int&nbsp;row,
                    int&nbsp;column)</pre>
<div class="block">Returns the value of this matrix at the specified row and column.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../com/aliasi/matrix/Matrix.html#value-int-int-">value</a></code>&nbsp;in interface&nbsp;<code><a href="../../../com/aliasi/matrix/Matrix.html" title="interface in com.aliasi.matrix">Matrix</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../com/aliasi/matrix/AbstractMatrix.html#value-int-int-">value</a></code>&nbsp;in class&nbsp;<code><a href="../../../com/aliasi/matrix/AbstractMatrix.html" title="class in com.aliasi.matrix">AbstractMatrix</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>row</code> - Row index.</dd>
<dd><code>column</code> - Column index.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The value of this matrix at the specified row and
 column.</dd>
</dl>
</li>
</ul>
<a name="singularValues--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>singularValues</h4>
<pre>public&nbsp;double[]&nbsp;singularValues()</pre>
<div class="block">Returns the array of singular values for this decomposition.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The singular values for this decomposition.</dd>
</dl>
</li>
</ul>
<a name="singularValue-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>singularValue</h4>
<pre>public&nbsp;double&nbsp;singularValue(int&nbsp;order)</pre>
<div class="block">Returns the singular value for the specified order.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>order</code> - Dimension of the singular value.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The singular value at the specified order.</dd>
</dl>
</li>
</ul>
<a name="leftSingularVectors--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>leftSingularVectors</h4>
<pre>public&nbsp;double[][]&nbsp;leftSingularVectors()</pre>
<div class="block">Returns a matrix in which the left singular vectors make up the
 columns.  The first index is for the row of the original matrix
 and the second index is for the order of the singular vector.
 Thus the returned matrix is <code>m&times;k</code>, if the
 original input was an <code>m&times;n</code> matrix and SVD was
 performed at order <code>k</code>.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The left singular vectors of this matrix.</dd>
</dl>
</li>
</ul>
<a name="rightSingularVectors--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rightSingularVectors</h4>
<pre>public&nbsp;double[][]&nbsp;rightSingularVectors()</pre>
<div class="block">Returns a matrix in which the right singular vectors make up
 the columns.  The first index is for the column of the original
 matrix and the second index is for the order of the singular
 vector.  Thus the returned matrix is <code>n&times;k</code>, if
 the original input was an <code>m&times;n</code> matrix and SVD
 was performed at order <code>k</code>.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The right singular vectors.</dd>
</dl>
</li>
</ul>
<a name="svd-double:A:A-int-double-double-double-double-com.aliasi.io.Reporter-double-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>svd</h4>
<pre>public static&nbsp;<a href="../../../com/aliasi/matrix/SvdMatrix.html" title="class in com.aliasi.matrix">SvdMatrix</a>&nbsp;svd(double[][]&nbsp;values,
                            int&nbsp;maxOrder,
                            double&nbsp;featureInit,
                            double&nbsp;initialLearningRate,
                            double&nbsp;annealingRate,
                            double&nbsp;regularization,
                            <a href="../../../com/aliasi/io/Reporter.html" title="class in com.aliasi.io">Reporter</a>&nbsp;reporter,
                            double&nbsp;minImprovement,
                            int&nbsp;minEpochs,
                            int&nbsp;maxEpochs)</pre>
<div class="block">Returns the signular value decomposition of the specified
 complete matrix of values.

 <p>For a full description of the arguments and values, see
 the method documentation for
 <a href="../../../com/aliasi/matrix/SvdMatrix.html#partialSvd-int:A:A-double:A:A-int-double-double-double-double-com.aliasi.io.Reporter-double-int-int-"><code>partialSvd(int[][],double[][],int,double,double,double,double,Reporter,double,int,int)</code></a>
 and the class documentation above.

 <p>The two-dimensional array of values must be an
 <code>m &times; n</code> matrix.  In particular, each row
 must be of the same length.  If this is not the case, an illegal
 argument exception will be raised.

 <p>This is now a utility method that calls <a href="../../../com/aliasi/matrix/SvdMatrix.html#svd-double:A:A-int-double-double-double-double-com.aliasi.io.Reporter-double-int-int-"><code>svd(double[][],int,double,double,double,double,Reporter,double,int,int)</code></a>
 with a reporter wrapping the specified print writer at the
 debug level, or a silent print writer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>values</code> - Array of values.</dd>
<dd><code>maxOrder</code> - Maximum order of the decomposition.</dd>
<dd><code>featureInit</code> - Initial value for singular vectors.</dd>
<dd><code>initialLearningRate</code> - Incremental multiplier of error
 determining how fast learning occurs.</dd>
<dd><code>annealingRate</code> - Rate at which annealing occurs; higher values
 provide more gradual annealing.</dd>
<dd><code>regularization</code> - A regularization constant to damp learning.</dd>
<dd><code>reporter</code> - Reporter to which to send progress and error
 reports.</dd>
<dd><code>minImprovement</code> - Minimum relative improvement in mean
 square error required to finish an epoch.</dd>
<dd><code>minEpochs</code> - Minimum number of epochs for training.</dd>
<dd><code>maxEpochs</code> - Maximum number of epochs for training.
 training, or <code>null</code> if no output is desired.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Singular value decomposition for the specified partial matrix
 at the specified order.</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/IllegalArgumentException.html?is-external=true" title="class or interface in java.lang">IllegalArgumentException</a></code> - Under conditions listed in the
 method documentation above.</dd>
</dl>
</li>
</ul>
<a name="partialSvd-int:A:A-double:A:A-int-double-double-double-double-com.aliasi.io.Reporter-double-int-int-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>partialSvd</h4>
<pre>public static&nbsp;<a href="../../../com/aliasi/matrix/SvdMatrix.html" title="class in com.aliasi.matrix">SvdMatrix</a>&nbsp;partialSvd(int[][]&nbsp;columnIds,
                                   double[][]&nbsp;values,
                                   int&nbsp;maxOrder,
                                   double&nbsp;featureInit,
                                   double&nbsp;initialLearningRate,
                                   double&nbsp;annealingRate,
                                   double&nbsp;regularization,
                                   <a href="../../../com/aliasi/io/Reporter.html" title="class in com.aliasi.io">Reporter</a>&nbsp;reporter,
                                   double&nbsp;minImprovement,
                                   int&nbsp;minEpochs,
                                   int&nbsp;maxEpochs)</pre>
<div class="block">Return the singular value decomposition of the specified
 partial matrix, using the specified search parameters.

 <p>The writer parameter may be set to allow incremental progress
 reports to that writer during training.  These report on RMSE
 per epoch.

 <p>See the class documentation above for a description of the
 algorithm.

 <p>There are a number of constraints on the input, any
 violation of which will raise an illegal argument exception.
 The conditions are:
 <ul>


 <li>The maximum order must be greater than zero.</li>

 <li>The minimum relative improvement in mean square error must be non-negative
 and finite.</li>

 <li>The minimum number of epochs must be greater than zero
 and less than or equal to the maximum number of epochs.</li>

 <li>The feature initialization value must be non-zero and finite.</li>

 <li>The learning rate must be positive and finite.</li>

 <li>The regularization parameter must be non-negative and finite.</li>

 <li>The column identitifer and value arrays must be the same
 length.</li>

 <li>The elements of the column identifier array and the
 value array must all be of the same length.</li>

 <li>All column identifiers must be non-negative.</li>

 <li>Each row of the column identifier matrix must contain
 columns in strictly ascending order.

 </ul></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>columnIds</code> - Identifiers of column index for given row and entry.</dd>
<dd><code>values</code> - Values at row and column index for given entry.</dd>
<dd><code>maxOrder</code> - Maximum order of the decomposition.</dd>
<dd><code>featureInit</code> - Initial value for singular vectors.</dd>
<dd><code>initialLearningRate</code> - Incremental multiplier of error determining how
 fast learning occurs.</dd>
<dd><code>annealingRate</code> - Rate at which annealing occurs; higher values
 provide more gradual annealing.</dd>
<dd><code>regularization</code> - A regularization constant to damp learning.</dd>
<dd><code>reporter</code> - Reporter to which progress reports are written, or
 <code>null</code> if no reporting is required.</dd>
<dd><code>minImprovement</code> - Minimum relative improvement in mean square error required
 to finish an epoch.</dd>
<dd><code>minEpochs</code> - Minimum number of epochs for training.</dd>
<dd><code>maxEpochs</code> - Maximum number of epochs for training.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Singular value decomposition for the specified partial matrix
 at the specified order.</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/IllegalArgumentException.html?is-external=true" title="class or interface in java.lang">IllegalArgumentException</a></code> - Under conditions listed in the
 method documentation above.</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../com/aliasi/matrix/SparseFloatVector.html" title="class in com.aliasi.matrix"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../com/aliasi/matrix/TaxicabDistance.html" title="class in com.aliasi.matrix"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?com/aliasi/matrix/SvdMatrix.html" target="_top">Frames</a></li>
<li><a href="SvdMatrix.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
