<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_45) on Sun Dec 04 16:36:10 EST 2016 -->
<title>ScoredPrecisionRecallEvaluation (LingPipe API)</title>
<meta name="date" content="2016-12-04">
<link rel="stylesheet" type="text/css" href="../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="ScoredPrecisionRecallEvaluation (LingPipe API)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":9,"i16":9,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../com/aliasi/classify/ScoredClassifierEvaluator.html" title="class in com.aliasi.classify"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../com/aliasi/classify/TfIdfClassifierTrainer.html" title="class in com.aliasi.classify"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?com/aliasi/classify/ScoredPrecisionRecallEvaluation.html" target="_top">Frames</a></li>
<li><a href="ScoredPrecisionRecallEvaluation.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">com.aliasi.classify</div>
<h2 title="Class ScoredPrecisionRecallEvaluation" class="title">Class ScoredPrecisionRecallEvaluation</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">java.lang.Object</a></li>
<li>
<ul class="inheritance">
<li>com.aliasi.classify.ScoredPrecisionRecallEvaluation</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public class <span class="typeNameLabel">ScoredPrecisionRecallEvaluation</span>
extends <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a></pre>
<div class="block">A <code>ScoredPrecisionRecallEvaluation</code> provides an
 evaluation based on the precision-recall operating points and
 sensitivity-specificity operating points.  The unscored
 precision-recall evaluation class is <a href="../../../com/aliasi/classify/PrecisionRecallEvaluation.html" title="class in com.aliasi.classify"><code>PrecisionRecallEvaluation</code></a>.

 <h3>Construction and Population</h3>

 <p>There is a single no-arg constructor <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#ScoredPrecisionRecallEvaluation--"><code>ScoredPrecisionRecallEvaluation()</code></a>.  

 <p>The method <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#addCase-boolean-double-"><code>addCase(boolean,double)</code></a> is used to populate
 the evaluation, with the first argument representing whether the
 response was correct and the second the score that was assigned.

 <h4>Missing Cases</h4>

 <p>If there are positive reference cases that are not added through
 <code>addCase()</code>, the total number of such cases should be added
 using the method <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#addMisses-int-"><code>addMisses(int)</code></a>.  This method effectively
 increments the number of reference positive cases used to compute
 recall values.

 <p>If there are negative reference cases that are not dealt with
 through <code>addCase()</code>, the method <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#addNegativeMisses-int-"><code>addNegativeMisses(int)</code></a> should be called with the total number of
 such cases as an argument.  This method increments the number of 
 reference engative cases used to compute specificity values.

 <h3>Example</h3>

 <P>By way of example, consider the following table of cases, all of
 which involve positive responses.  The cases are in rank order, but
 may be added in any order.  

 <blockquote>
 <table border="1" cellpadding="5">
 <tr><td><i>Rank</i></td>
     <td><i>Score</i></td>
     <td><i>Correct</i></td>
     <td><i>TP</i></td>
     <td><i>TN</i></td>
     <td><i>FP</i></td>
     <td><i>FN</i></td>
     <td><i>Rec</i></td>
     <td><i>Prec</i></td>
     <td><i>Spec</i></td>
     <td><i>F Meas</i></td></tr>
 <tr><td>(-1)</td><td>n/a</td><td>n/a</td>
     <td>0</td> <td>6</td> <td>0</td> <td>5</td>
     <td>0.00</td>
     <td bgcolor="yellow">1.00</td>
     <td bgcolor="orange">1.00</td>
     <td>0.00</td></tr>
 <tr><td colspan="11"> </td></tr>
 <tr><td>0</td><td>-1.21</td><td>no</td>
     <td>0</td> <td>5</td> <td>1</td> <td>5</td>
     <td>0.00</td>
     <td>0.00</td>
     <td>0.83</td>
     <td>0.00</td></tr>
 <tr bgcolor="#CCCCFF"><td>1</td><td>-1.27</td><td>yes</td>
     <td>1</td> <td>5</td> <td>1</td> <td>4</td>
     <td>0.20</td>
     <td>0.50</td>
     <td bgcolor="orange">0.83</td>
     <td>0.29</td></tr>
 <tr><td>2</td><td>-1.39</td><td>no</td>
     <td>1</td> <td>4</td> <td>2</td> <td>4</td>
     <td>0.20</td>
     <td>0.33</td>
     <td>0.67</td>
     <td>0.25</td></tr>
 <tr bgcolor="#CCCCFF"><td>3</td><td>-1.47</td><td>yes</td>
     <td>2</td> <td>4</td> <td>2</td> <td>3</td>
     <td>0.40</td>
     <td>0.50</td>
     <td>0.67</td>
     <td>0.44</td></tr>
 <tr bgcolor="#CCCCFF"><td>4</td><td>-1.60</td><td>yes</td>
     <td>3</td> <td>4</td> <td>2</td> <td>2</td>
     <td>0.60</td>
     <td bgcolor="yellow">0.60</td>
     <td bgcolor="orange">0.67</td>
     <td bgcolor="pink">0.60</td></tr>
 <tr><td>5</td><td>-1.65</td><td>no</td>
     <td>3</td> <td>3</td> <td>3</td> <td>2</td>
     <td>0.60</td>
     <td>0.50</td>
     <td>0.50</td>
     <td>0.55</td></tr>
 <tr><td>6</td><td>-1.79</td><td>no</td>
     <td>3</td> <td>2</td> <td>4</td> <td>2</td>
     <td>0.60</td>
     <td>0.43</td>
     <td>0.33</td>
     <td>0.50</td></tr>
 <tr><td>7</td><td>-1.80</td><td>no</td>
     <td>3</td> <td>1</td> <td>5</td> <td>2</td>
     <td>0.60</td>
     <td>0.38</td>
     <td>0.17</td>
     <td>0.47</td></tr>
 <tr bgcolor="#CCCCFF"><td>8</td><td>-2.01</td><td>yes</td>
     <td>4</td> <td>1</td> <td>5</td> <td>1</td>
     <td>0.80</td>
     <td bgcolor="yellow">0.44</td>
     <td bgcolor="orange">0.17</td>
     <td>0.53</td></tr>
 <tr><td>9</td><td>-3.70</td><td>no</td>
     <td>4</td> <td>0</td> <td>6</td> <td>1</td>
     <td>0.80</td>
     <td>0.40</td>
     <td>0.00</td>
     <td>0.53</td></tr>
 <tr><td colspan="11"> </td></tr>
 <tr><td>?</td><td>n/a</td><td>yes</td>
     <td>5</td> <td>0</td> <td>6</td> <td>0</td>
     <td>1.00</td>
     <td bgcolor="yellow">0.00</td>
     <td bgcolor="orange">0.00</td>
     <td>0.00</td></tr>
 </table>
 </blockquote>

 The first line, which is separated, indicates the values before any
 results have been returned.  There's no score corresponding to this
 operating point, and given that it doesn't correspond to a result,
 correctness is not applicable.  It has zero recall, one
 specificity, and one precision (letting zero divided by zero be one
 here).

 <p>The next lines, listed as ranks 0 to 9, correspond to calls to
 <code>addCase()</code> with the specified score and correctness.  For
 each of these lines, we list the corresponding number of true
 positives (TP), true negatives (TN), false positives (FP), and
 false negatives (FN).  These are followed by recall, precision and
 specificity (aka rejection recall).  See the class documentation
 for <a href="../../../com/aliasi/classify/PrecisionRecallEvaluation.html" title="class in com.aliasi.classify"><code>PrecisionRecallEvaluation</code></a> for definitions of these
 values in terms of the TP, TN, FP, and FN counts.

 <p>There are five positive reference cases (blue backgrounds) and
 six negative reference cases (clear backgrounds) in this diagram.
 The yellow precision values and orange specificity values are used
 for interpolated curves.

 <h3>Precision-Recall Curves</h3>
 
 <P>The pairs of precision/recall values form the basis for the
 precision-recall curve returned by <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#prCurve-boolean-"><code>prCurve(boolean)</code></a>, with
 the argument indicating whether to perform precision interpolation.
 For the above graph, the uninterpolated precision-recall curve is:

 <blockquote><pre>
 <b>prCurve</b>(false) = {
     { 0.00, 1.00 },
     { 0.20, 0.50 },
     { 0.20, 0.33 },
     { 0.40, 0.50 },
     { 0.60, 0.60 },
     { 0.60, 0.50 },
     { 0.60, 0.43 },
     { 0.60, 0.38 },
     { 0.60, 0.38 },
     { 0.80, 0.44 },
     { 0.80, 0.40 },
     { 1.00, 0.00 }
 }</pre></blockquote>
 
 Typically, a form of interpolation is performed that sets the
 precision for a given recall value to the maximum of the precision
 at the curent or greater recall value.  This pushes the yellow
 precision values up the graph.  At the same time, we only return
 values that correspond to jumps in recall, corresponding to ranks
 at which true positives were returned.  For the example above,
 the result is

 <blockquote><pre>
 <b>prCurve</b>(true) = {
     { 0.00, 1.00 },
     { 0.20, 0.60 },
     { 0.40, 0.60 },
     { 0.60, 0.60 },
     { 0.80, 0.44 },
     { 1.00, 0.00 }
 }</pre></blockquote>

 For convenience, the evaluation always adds the two limit points,
 one with precision 0 and recall 1, and one with precision 1 and
 recall 0.  These operating points are always achievable, the first
 by returning every possible answer, and the second by returning no
 answers.  

 <h3>ROC Curves</h3>

 Another popular graph for visualizing classification results is the
 receiver operating characteristic (ROC) curve, which plots
 sensitivity (a.k.a. recall) versus one minus specificity
 (a.k.a. one minus rejection recall).  Because specificity is
 accuracy on negative cases and sensitivity accuracy on positive
 cases, these graphs are fairly easy to interpret.  The
 precision-recall curve, on the othe hand, does not consider true
 negative (TN) counts.
 
 <p>The ROC curve is returned by the method <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#rocCurve-boolean-"><code>rocCurve(boolean)</code></a> with the boolean parameter again indicating
 whether to perform precision interpolation.  For the above graph,
 the result is:

 <blockquote><pre>
 <b>rocCurve</b>(false) = {
     { 1 - 1.00, 0.00 },
     { 1 - 0.83, 0.00 },
     { 1 - 0.83, 0.20 },
     { 1 - 0.67, 0.20 },
     { 1 - 0.67, 0.40 },
     { 1 - 0.67, 0.60 },
     { 1 - 0.50, 0.60 },
     { 1 - 0.33, 0.60 },
     { 1 - 0.17, 0.60 },
     { 1 - 0.17, 0.80 },
     { 1 - 0.00, 0.80 },
     { 1 - 0.00, 1.00 }
 }</pre></blockquote>

 Interpolation works exactly the same way as for the precision-recall
 curves, but based on specificity rather than precsion.

 <blockquote><pre>
 <b>rocCurve</b>(true) = {
     { 1 - 1.00, 0.00 },
     { 1 - 0.83, 0.20 },
     { 1 - 0.67, 0.60 },
     { 1 - 0.50, 0.60 },
     { 1 - 0.33, 0.60 },
     { 1 - 0.17, 0.80 },
     { 1 - 0.00, 1.00 }
 }</pre></blockquote>


 <h3>Precision at <i>N</i></h3>

 <p>In some information extraction or retrieval tasks, a system
 might only return a fixed number of examples to a user.  To
 evaluate the result of such truncated result sets, it is common to
 report the precision after <i>N</i> returned results.  The counting
 starts from one rather than zero for returned results, but we fill in
 a limiting value of 1.0 for precision at 0.  In our running
 example, we have

 <pre>
      <b>precisionAt</b>(0) = 1.0
      <b>precisionAt</b>(1) = 0.0
      <b>precisionAt</b>(5) = 0.6
      <b>precisionAt</b>(10) = 0.4
      <b>precisionAt</b>(20) = 0.2
      <b>precisionAt</b>(100) = 0.04</pre>

 The return value for a rank greater than the number of cases added
 will be calculated assuming all other results are errors.
 
 <h3>Reciprocal Rank</h3>

 For information extraction tasks, one result is often enough to
 satisfy an information need.  A popular measure to characterize
 this situation is reciprocal rank.  The reciprocal rank is defined
 to be <code>1/<i>M</i></code>, where <code><i>M</i></code> is the
 rank (counting from 1) of the first true positive return.  In our
 running example, the first result is a false positive and the
 second a true positive, so reciprocal rank is

 <pre>
      <b>reciprocalRank()</b>() = 0.5</pre>

 Note that this measure emphasizes differences in early ranks
 much more than later ones.  For instance, the reciprocal rank
 for a system returning a correct result first is 1/1, but
 for one returning it second, it's 1/2, and for one returning
 the first true positive at rank 10, it's 1/10.  The difference
 between rank 1 and 2 is greater than that between 2 and 10. 

 <h3>R Precision</h3>

 The R precision is defined as the precision for the first R
 results, where R is the number of reference positive cases.  If
 there are not enough results, the value returned is calculated by
 assuming all the non-added results are errors.  

 <p>For the running example, R precision is

 <blockquote><pre>
 <b>rPrecision</b>() = 0.6</pre></blockquote>

 R precision will always be at a point where precision equals
 recall.  It is also known as the precision-recall break-even point
 (BEP), and for convenience, there is a method of that name,

 <blockquote><pre>
 <b>prBreakevenPoint</b>() = rPrecision() = 0.6</pre></blockquote>

 <h3>Maximum F Measure</h3>

 Another commonly reported statistic that may be calculated from the
 precisino-recall curve is the maximum F measure (see <a href="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fMeasure-double-double-double-"><code>PrecisionRecallEvaluation.fMeasure(double,double,double)</code></a> for a
 definition of F measure).  The result is the maximum F measure
 value achieved at any position on the curve.  For our example, this
 arises at

 <blockquote><pre>
 maximumFMeasure() = 0.6</pre></blockquote>

 <p>In general, the maximum F measure may occur at a point
 other than the precision-recall break-even point.

 <h3>Averaged Results</h3>

 If there is more than one classifier or information extractor
 being evaluated, it is common to report averages of several
 of the statistics reported by this class.  LingPipe does not compute
 these values, but they are easy to calculate by accumulating
 results for individual ranked precision-recall evaluations.

 <p>The average across multiple evaluations of average precision is
 somewhat misleadingly called mean average precision (MAP) [it should
 be average average precision, because averages are over finite
 samples and means are properties of distributions].

 <p>The eleven-point precision-recall curves, reciprocal rank, and R
 precision are also popular targets for reporting averaged results.

 <h3>References</h3>

 For texts on ROC and PR evaluations, see the following.

 <ul> 
 
 <li>Wikipedia. <a
 href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">Receiver
 Operating Characteristic</a>.

 <li>Lasko, Thomas A., Jui G. Bhagwat, Kelly H. Zou, and Lucila Ohno-Machado.
 2005. The use of receiver operating
 characteristic curves in biomedical informatics.  <i>Journal of
 Biomedical Informatics</i> <b>38</b>:404–-415.</li>

 <li> Manning, Christopher D., Prabhakar Raghavan, and Hinrich
 Sch&#252;tze. 2008. <i> Introduction to Information Retrieval</i>. Cambridge
 University Press.  Chapter 8, Evaluation in information retrieval.</li>
 </ul></div>
<dl>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>LingPipe2.1</dd>
<dt><span class="simpleTagLabel">Version:</span></dt>
<dd>4.0.1</dd>
<dt><span class="simpleTagLabel">Author:</span></dt>
<dd>Bob Carpenter, Mike Ross, Breck Baldwin</dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#FLOATING_POINT_EQUALS_EPSILON">FLOATING_POINT_EQUALS_EPSILON</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#ScoredPrecisionRecallEvaluation--">ScoredPrecisionRecallEvaluation</a></span>()</code>
<div class="block">Construct a scored precision-recall evaluation.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#addCase-boolean-double-">addCase</a></span>(boolean&nbsp;correct,
       double&nbsp;score)</code>
<div class="block">Add a case with the specified correctness and response score.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#addMisses-int-">addMisses</a></span>(int&nbsp;count)</code>
<div class="block">Incrments the positive reference count without adding a
 case from the classifier.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#addNegativeMisses-int-">addNegativeMisses</a></span>(int&nbsp;count)</code>
<div class="block">Incrments the negative reference count without adding a case
 from the classifier.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#areaUnderPrCurve-boolean-">areaUnderPrCurve</a></span>(boolean&nbsp;interpolate)</code>
<div class="block">Returns the area under the curve (AUC) for the recall-precision
 curve with interpolation as specified.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#areaUnderRocCurve-boolean-">areaUnderRocCurve</a></span>(boolean&nbsp;interpolate)</code>
<div class="block">Returns the area under the receiver operating characteristic
 (ROC) curve.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#averagePrecision--">averagePrecision</a></span>()</code>
<div class="block">Returns the average of precisions at the true positive
 results.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>double[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#elevenPtInterpPrecision--">elevenPtInterpPrecision</a></span>()</code>
<div class="block">Returns the interpolated precision at eleven recall points
 evenly spaced between 0 and 1.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#maximumFMeasure--">maximumFMeasure</a></span>()</code>
<div class="block">Returns the maximum F<sub><sub>1</sub></sub>-measure for an
 operating point on the PR curve.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#maximumFMeasure-double-">maximumFMeasure</a></span>(double&nbsp;beta)</code>
<div class="block">Returns the maximum F<sub><sub>&beta;</sub></sub>-measure for
 an operating point on the precision-recall curve for a
 specified precision weight <code>&beta; &gt; 0</code>.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#numCases--">numCases</a></span>()</code>
<div class="block">Returns the total number of positive and negative reference
 cases for this evaluation.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#numNegativeRef--">numNegativeRef</a></span>()</code>
<div class="block">Return the number of negative reference cases.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#numPositiveRef--">numPositiveRef</a></span>()</code>
<div class="block">Returns the number of positive reference cases.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#prBreakevenPoint--">prBreakevenPoint</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>double[][]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#prCurve-boolean-">prCurve</a></span>(boolean&nbsp;interpolate)</code>
<div class="block">Returns the precision-recall curve, interpolating if
 the specified flag is true.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#precisionAt-int-">precisionAt</a></span>(int&nbsp;rank)</code>
<div class="block">Returns the precision score achieved by returning the top
 scoring documents up to (but not including) the specified rank.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#printPrecisionRecallCurve-double:A:A-java.io.PrintWriter-">printPrecisionRecallCurve</a></span>(double[][]&nbsp;prCurve,
                         <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/io/PrintWriter.html?is-external=true" title="class or interface in java.io">PrintWriter</a>&nbsp;pw)</code>
<div class="block">Prints a precision-recall curve with F-measures.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#printScorePrecisionRecallCurve-double:A:A-java.io.PrintWriter-">printScorePrecisionRecallCurve</a></span>(double[][]&nbsp;prScoreCurve,
                              <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/io/PrintWriter.html?is-external=true" title="class or interface in java.io">PrintWriter</a>&nbsp;pw)</code>
<div class="block">Prints a precision-recall curve with score.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>double[][]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#prScoreCurve-boolean-">prScoreCurve</a></span>(boolean&nbsp;interpolate)</code>
<div class="block">Returns the array of recall/precision/score operating points
 according to the scores of the cases.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#reciprocalRank--">reciprocalRank</a></span>()</code>
<div class="block">Returns the reciprocal rank for this evaluation.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>double[][]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#rocCurve-boolean-">rocCurve</a></span>(boolean&nbsp;interpolate)</code>
<div class="block">Returns the receiver operating characteristic (ROC) curve for
 the cases ordered by score, interpolating if the specified flag
 is <code>true</code>.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#rPrecision--">rPrecision</a></span>()</code>
<div class="block">Return the R precision.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/String.html?is-external=true" title="class or interface in java.lang">String</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#toString--">toString</a></span>()</code>
<div class="block">Returns a string-based representation of this scored precision
 recall evaluation.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.<a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a></h3>
<code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#clone--" title="class or interface in java.lang">clone</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#equals-java.lang.Object-" title="class or interface in java.lang">equals</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#finalize--" title="class or interface in java.lang">finalize</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#getClass--" title="class or interface in java.lang">getClass</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#hashCode--" title="class or interface in java.lang">hashCode</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#notify--" title="class or interface in java.lang">notify</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#notifyAll--" title="class or interface in java.lang">notifyAll</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait--" title="class or interface in java.lang">wait</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait-long-" title="class or interface in java.lang">wait</a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait-long-int-" title="class or interface in java.lang">wait</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="FLOATING_POINT_EQUALS_EPSILON">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>FLOATING_POINT_EQUALS_EPSILON</h4>
<pre>public static final&nbsp;double FLOATING_POINT_EQUALS_EPSILON</pre>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../constant-values.html#com.aliasi.classify.ScoredPrecisionRecallEvaluation.FLOATING_POINT_EQUALS_EPSILON">Constant Field Values</a></dd>
</dl>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="ScoredPrecisionRecallEvaluation--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>ScoredPrecisionRecallEvaluation</h4>
<pre>public&nbsp;ScoredPrecisionRecallEvaluation()</pre>
<div class="block">Construct a scored precision-recall evaluation.</div>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="addCase-boolean-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addCase</h4>
<pre>public&nbsp;void&nbsp;addCase(boolean&nbsp;correct,
                    double&nbsp;score)</pre>
<div class="block">Add a case with the specified correctness and response score.
 Only positive response cases are considered, and the correct
 flag is set to <code>true</code> if the reference was also
 positive.  The score is just the response score.

 <P><b>Warning:</b> The scores should be sensibly comparable
 across cases.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>correct</code> - <code>true</code> if this case was correct.</dd>
<dd><code>score</code> - Score of response.</dd>
</dl>
</li>
</ul>
<a name="addMisses-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addMisses</h4>
<pre>public&nbsp;void&nbsp;addMisses(int&nbsp;count)</pre>
<div class="block">Incrments the positive reference count without adding a
 case from the classifier. This method is used for
 precision-recall evaluations where the set of returned items
 does not enumerate all positive references.  These misses are
 used in calcuating statistics such as precision-recall curves.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>count</code> - Number of outright misses to add to
 this evaluation.</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/IllegalArgumentException.html?is-external=true" title="class or interface in java.lang">IllegalArgumentException</a></code> - if the count is not positive.</dd>
</dl>
</li>
</ul>
<a name="addNegativeMisses-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addNegativeMisses</h4>
<pre>public&nbsp;void&nbsp;addNegativeMisses(int&nbsp;count)</pre>
<div class="block">Incrments the negative reference count without adding a case
 from the classifier. This method is used for ROC evaluations
 where the set of returned items does not enumerate all negative
 references.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>count</code> - Number of outright misses to add to
 this evaluation.</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/IllegalArgumentException.html?is-external=true" title="class or interface in java.lang">IllegalArgumentException</a></code> - if the count is not positive.</dd>
</dl>
</li>
</ul>
<a name="numCases--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numCases</h4>
<pre>public&nbsp;int&nbsp;numCases()</pre>
<div class="block">Returns the total number of positive and negative reference
 cases for this evaluation.  The return value is the sum of
 <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#numPositiveRef--"><code>numPositiveRef()</code></a> and <code>#numNegativeRef()</code>.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The number of cases for this evaluation.</dd>
</dl>
</li>
</ul>
<a name="numPositiveRef--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numPositiveRef</h4>
<pre>public&nbsp;int&nbsp;numPositiveRef()</pre>
<div class="block">Returns the number of positive reference cases.  This count
 includes the number of cases added with flag <code>true</code> plus
 the number of misses added.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Number of positive reference cases.</dd>
</dl>
</li>
</ul>
<a name="numNegativeRef--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numNegativeRef</h4>
<pre>public&nbsp;int&nbsp;numNegativeRef()</pre>
<div class="block">Return the number of negative reference cases.  The count
 includes the number of cases added with flag <code>false</code> plus
 the number of negative misses added.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Number of negative reference cases.</dd>
</dl>
</li>
</ul>
<a name="rPrecision--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rPrecision</h4>
<pre>public&nbsp;double&nbsp;rPrecision()</pre>
<div class="block">Return the R precision.  See the class documentation above for
 a definition.  The R-precision operating point has identical
 precision and recall by definition.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The R precision.</dd>
</dl>
</li>
</ul>
<a name="elevenPtInterpPrecision--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>elevenPtInterpPrecision</h4>
<pre>public&nbsp;double[]&nbsp;elevenPtInterpPrecision()</pre>
<div class="block">Returns the interpolated precision at eleven recall points
 evenly spaced between 0 and 1.  The recall points are { 0.0,
 0.1, 0.2, ..., 1.0 }.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Eleven-point interpolated precision.</dd>
</dl>
</li>
</ul>
<a name="averagePrecision--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>averagePrecision</h4>
<pre>public&nbsp;double&nbsp;averagePrecision()</pre>
<div class="block">Returns the average of precisions at the true positive
 results.  If an item is missed (i.e., it was added
 by <code>#addMisses(int)</code>, the precision is considered
 to be zero.  (See class documentation for more information.)</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Average precision at each true positive.</dd>
</dl>
</li>
</ul>
<a name="prCurve-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>prCurve</h4>
<pre>public&nbsp;double[][]&nbsp;prCurve(boolean&nbsp;interpolate)</pre>
<div class="block">Returns the precision-recall curve, interpolating if
 the specified flag is true.  See the class documentation
 above for a definition of the curve.

 <p><i>Warning:</i> Despite the name, the values
 returned are in the arrays with recall at index 0
 and precision at index 1.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>interpolate</code> - Set to <code>true</code> for precision
 interpolation.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The precision-recall curve.</dd>
</dl>
</li>
</ul>
<a name="prScoreCurve-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>prScoreCurve</h4>
<pre>public&nbsp;double[][]&nbsp;prScoreCurve(boolean&nbsp;interpolate)</pre>
<div class="block">Returns the array of recall/precision/score operating points
 according to the scores of the cases.  Other than adding
 scores, this method works just like <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#prCurve-boolean-"><code>prCurve(boolean)</code></a>.
 Index 0 is recall, 1 is precision and 2 is the score.
 <p>.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>interpolate</code> - Set to <code>true</code> if the precisions
 are interpolated through pruning dominated points.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The precision-recall-score curve for the specified category.</dd>
</dl>
</li>
</ul>
<a name="rocCurve-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rocCurve</h4>
<pre>public&nbsp;double[][]&nbsp;rocCurve(boolean&nbsp;interpolate)</pre>
<div class="block">Returns the receiver operating characteristic (ROC) curve for
 the cases ordered by score, interpolating if the specified flag
 is <code>true</code>.  See the class documentation above for
 a definition and example of the returned curve.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>interpolate</code> - Interpolate specificity values.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The receiver operating characteristic curve.</dd>
</dl>
</li>
</ul>
<a name="maximumFMeasure--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maximumFMeasure</h4>
<pre>public&nbsp;double&nbsp;maximumFMeasure()</pre>
<div class="block">Returns the maximum F<sub><sub>1</sub></sub>-measure for an
 operating point on the PR curve.  See the class documentation
 above for an example and further explanation.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Maximum f-measure for the specified category.</dd>
</dl>
</li>
</ul>
<a name="maximumFMeasure-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maximumFMeasure</h4>
<pre>public&nbsp;double&nbsp;maximumFMeasure(double&nbsp;beta)</pre>
<div class="block">Returns the maximum F<sub><sub>&beta;</sub></sub>-measure for
 an operating point on the precision-recall curve for a
 specified precision weight <code>&beta; &gt; 0</code>.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Maximum f-measure for the specified category.</dd>
</dl>
</li>
</ul>
<a name="precisionAt-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>precisionAt</h4>
<pre>public&nbsp;double&nbsp;precisionAt(int&nbsp;rank)</pre>
<div class="block">Returns the precision score achieved by returning the top
 scoring documents up to (but not including) the specified rank.
 The precision-recall curve is not interpolated for this
 computation.  For rank 0, the result <code>Double.NaN</code> is
 returned.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The precision at the specified rank.</dd>
</dl>
</li>
</ul>
<a name="prBreakevenPoint--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>prBreakevenPoint</h4>
<pre>public&nbsp;double&nbsp;prBreakevenPoint()</pre>
</li>
</ul>
<a name="reciprocalRank--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reciprocalRank</h4>
<pre>public&nbsp;double&nbsp;reciprocalRank()</pre>
<div class="block">Returns the reciprocal rank for this evaluation.  The reciprocal
 rank is defined as the reciprocal <code>1/N</code> of the
 rank <code>N</code> at which the first true positive is found.
 This method counts ranks from 1 rather than 0.

 The return result will be between 1.0 for the first-best result
 being correct and 0.0, for none of the results being correct.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The reciprocal rank.</dd>
</dl>
</li>
</ul>
<a name="areaUnderPrCurve-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>areaUnderPrCurve</h4>
<pre>public&nbsp;double&nbsp;areaUnderPrCurve(boolean&nbsp;interpolate)</pre>
<div class="block">Returns the area under the curve (AUC) for the recall-precision
 curve with interpolation as specified.  See the class documentation
 for more information.

 <p><b>Warning:</b> This method uses the parallelogram method
 for interpolation rather than the usual interpolation method
 used to calculate AUC for precision-recall in information
 retrieval evaluations.  The usual AUC calculation for PR curves</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>interpolate</code> - Set to <code>true</code> to interpolate
 the precision values.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The area under the specified precision-recall curve.</dd>
</dl>
</li>
</ul>
<a name="areaUnderRocCurve-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>areaUnderRocCurve</h4>
<pre>public&nbsp;double&nbsp;areaUnderRocCurve(boolean&nbsp;interpolate)</pre>
<div class="block">Returns the area under the receiver operating characteristic
 (ROC) curve.  See the class documentation for more information.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>interpolate</code> - Set to <code>true</code> to interpolate
 the rejection recall values.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The area under the ROC curve.</dd>
</dl>
</li>
</ul>
<a name="toString--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toString</h4>
<pre>public&nbsp;<a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/String.html?is-external=true" title="class or interface in java.lang">String</a>&nbsp;toString()</pre>
<div class="block">Returns a string-based representation of this scored precision
 recall evaluation.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#toString--" title="class or interface in java.lang">toString</a></code>&nbsp;in class&nbsp;<code><a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</a></code></dd>
</dl>
</li>
</ul>
<a name="printPrecisionRecallCurve-double:A:A-java.io.PrintWriter-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>printPrecisionRecallCurve</h4>
<pre>public static&nbsp;void&nbsp;printPrecisionRecallCurve(double[][]&nbsp;prCurve,
                                             <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/io/PrintWriter.html?is-external=true" title="class or interface in java.io">PrintWriter</a>&nbsp;pw)</pre>
<div class="block">Prints a precision-recall curve with F-measures.  The curve is formatted
 as in <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#prCurve-boolean-"><code>prCurve(boolean)</code></a>: an array of length-2 arrays of doubles.
 In each length-2 array, the recall value is at index 0, and the precision
 is at index 1.  The printed curve prints 3 columns in the following order:
 precision, recall, F-measure.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>prCurve</code> - A precision-recall curve.</dd>
<dd><code>pw</code> - The output PrintWriter.</dd>
</dl>
</li>
</ul>
<a name="printScorePrecisionRecallCurve-double:A:A-java.io.PrintWriter-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>printScorePrecisionRecallCurve</h4>
<pre>public static&nbsp;void&nbsp;printScorePrecisionRecallCurve(double[][]&nbsp;prScoreCurve,
                                                  <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/io/PrintWriter.html?is-external=true" title="class or interface in java.io">PrintWriter</a>&nbsp;pw)</pre>
<div class="block">Prints a precision-recall curve with score.  The curve is formatted
 as in <a href="../../../com/aliasi/classify/ScoredPrecisionRecallEvaluation.html#prScoreCurve-boolean-"><code>prScoreCurve(boolean)</code></a>: an array of length-3 arrays of doubles.
 In each length-3 array, the recall value is at index 0, and the precision
 is at index 1 and score at 2.  The printed curve prints 3 columns in the following order:
 precision, recall, score.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>prScoreCurve</code> - A precision-recall score curve.</dd>
<dd><code>pw</code> - The output PrintWriter.</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../com/aliasi/classify/ScoredClassifierEvaluator.html" title="class in com.aliasi.classify"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../com/aliasi/classify/TfIdfClassifierTrainer.html" title="class in com.aliasi.classify"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?com/aliasi/classify/ScoredPrecisionRecallEvaluation.html" target="_top">Frames</a></li>
<li><a href="ScoredPrecisionRecallEvaluation.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
